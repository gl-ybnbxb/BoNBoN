{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742463f7-5517-40da-bc6f-4ed3b3d3089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "from build_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39aee2-26c3-4b51-925b-dac46f9972b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the device\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff555c5-aa7b-4a4c-a1df-d8809b33b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv('hh_prompt_subset.csv')\n",
    "prompts = df['Prompt'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c2448d-8109-43e3-bada-8714c21283f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reference model and its tokenizer\n",
    "ref_model = AutoModelForCausalLM.from_pretrained(args.ref_model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.ref_model_dir, padding=True, padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108ab7f-beac-4d00-9eaf-b49bfd50dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the reward model and its tokenizer\n",
    "rw_model = AutoModelForSequenceClassification.from_pretrained(args.reward_model_dir)\n",
    "rw_tokenizer = AutoTokenizer.from_pretrained(args.reward_model_dir, padding_side='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7916e-ccf6-4139-8c85-6d7f58746326",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {\"min_length\": -1, \"top_k\": 0.0, \"top_p\": 1.0,\n",
    "              \"do_sample\": True, \"pad_token_id\": tokenizer.eos_token_id, 'temperature': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c6e593-194b-4b8f-aeb2-29f4dccb6866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move all the models to gpus\n",
    "ref_model.to(device)\n",
    "rw_model.to(device)\n",
    "ref_model.eval()\n",
    "rw_model.eval()\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9df87-6bc7-4fb1-a39d-4049a01f4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best and worst data\n",
    "best_worst_ds = best_and_worst_of_n_sampler(prompts, batch_size=2, max_len=256, \n",
    "                                            model = ref_model, tokenizer = tokenizer, rw_model = rw_model, rw_tokenizer= rw_tokenizer,\n",
    "                                            device = device, gen_kwargs = gen_kwargs, n_seq=[3,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7fa708-2d2c-42cb-b38b-9e447a1fe938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data     \n",
    "for pn in [3,8]:\n",
    "    dict_to_save = dict(best_worst_ds[pn])\n",
    "\n",
    "    full_filename = f'/best-of-{pn}/bw_maxlen_{args.maxlen}.jsonl'\n",
    "    with open(full_filename, 'w') as f:\n",
    "        for key, value in dict_to_save.items():\n",
    "            json_record = json.dumps({key: value})\n",
    "            f.write(json_record + '\\n')\n",
    "\n",
    "    print(f'Best of {pn} data saved to {full_filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
